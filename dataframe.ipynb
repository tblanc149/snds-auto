{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ffeb03ae",
      "metadata": {
        "id": "ffeb03ae"
      },
      "source": [
        "# <u>Outils d'Automatisation des Tables SNDS</u>\n",
        "\n",
        "## Contexte\n",
        "Dans le cadre du projet complexe de l'IMT Atlantique nommé **\"Visualisation des Parcours de Soins\"**, nous avons développé un outil permettant de récupérer et traiter les informations des patients présentes dans la base de données SNDS (Système National des Données de Santé).\n",
        "\n",
        "## Objectifs\n",
        "L'objectif principal de cet outil est de :\n",
        "- Récupérer les informations des patients à partir des tables SNDS.\n",
        "- Extraire des motifs (patterns) pour permettre une visualisation des séquences d'actes médicaux.\n",
        "- Faciliter l'analyse pour extraire les parcours de soins.\n",
        "\n",
        "## Tables Utilisées\n",
        "L'outil permet de récupérer et traiter les tables suivantes :\n",
        "- **ir_ben_r** : Informations sur les bénéficiaires.\n",
        "- **er_prs_f** : Prestations.\n",
        "- **er_pha_f** : Pharmacies.\n",
        "- **ir_pha_r** : Référentiel des médicaments.\n",
        "- **er_bio_f** : Actes de biologie.\n",
        "- **er_cam_f** : Actes de médicaux.\n",
        "- **er_tip_f** : équipements médicaux.\n",
        "- **er_ete_f** : Établissements.\n",
        "- **t_mco23a, t_mco23b, t_mco23c, t_mco23d** : Hospitalisations pour l'année 2023.\n",
        "- **t_mco22a, t_mco22b, t_mco22c, t_mco22d** : Hospitalisations pour l'année 2022.\n",
        "\n",
        "## Fonctionnalités\n",
        "L'outil permet de :\n",
        "- **Extraire les informations essentielles** pour les économistes de la santé et les analystes de parcours de soins.\n",
        "- **Automatiser le traitement des données** pour faciliter l'analyse et la visualisation des parcours de soins.\n",
        "- **Adapter les extractions** selon les besoins spécifiques des utilisateurs.\n",
        "\n",
        "## Utilisation\n",
        "Le code est commenté et expliqué pour être le plus adaptable possible aux besoins des utilisateurs. Voici quelques points clés :\n",
        "- **Commentaires détaillés** : Chaque section du code est commentée pour expliquer son rôle et son fonctionnement.\n",
        "- **Adaptabilité** : Les utilisateurs peuvent facilement modifier les extractions et les analyses selon leurs besoins spécifiques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f9ca9d",
      "metadata": {
        "id": "04f9ca9d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31959cb",
      "metadata": {
        "id": "a31959cb"
      },
      "source": [
        "# <u>Chargements des données</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12cc1de0",
      "metadata": {
        "id": "12cc1de0"
      },
      "source": [
        "Ci-desous se trouve la liste des tables utilisées.\n",
        "\n",
        "#### **Adaptation des Noms de Fichiers**\n",
        "\n",
        "En fonction des noms des tables que vous utilisez dans votre base de données, il pourrait être nécessaire d'adapter les noms dans le code.\n",
        "\n",
        "\n",
        "\n",
        "#### **Exemple d'Adaptation**\n",
        "\n",
        "Si vos fichiers ont des noms différents de ceux utilisés dans le code, vous devez modifier les noms des variables pour qu'ils correspondent aux noms de vos fichiers.\n",
        "   Exemple de nom de fichier            | Nom dans le code          |\n",
        " |---------------------------|-------------------------------------|\n",
        " | `table_des_prestations.xlsx`    |  \"table_des_prestations\"      |\n",
        "\n",
        " Conseil : garder les mêmes noms de tables que dans notre outil pour limiter les changements dans l'ensemble du code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97f97fd",
      "metadata": {
        "id": "f97f97fd"
      },
      "outputs": [],
      "source": [
        "# Liste des tables à charger\n",
        "tables_snds = [\n",
        "    \"er_prs_f\", \"er_pha_f\", \"ir_pha_r\", \"er_bio_f\", \"er_cam_f\",\n",
        "    \"er_tip_f\", \"er_ete_f\", \"t_mco23b\", \"t_mco23c\", \"t_mco23a\", \"t_mco23d\", \"t_mco22b\", \"t_mco22c\", \"t_mco22a\", \"t_mco22d\",\"ir_ben_r\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d65765d",
      "metadata": {
        "id": "1d65765d"
      },
      "source": [
        "Nous travaillons dans le cadre de notre projet avec des tables Excel. Utilisez la fonction suivante :\n",
        "\n",
        "```python\n",
        "data_dict[table] = pd.read_excel(file_path, dtype={'BEN_NIR_PSA': str, 'BEN_NIR_ANO': str})\n",
        "```\n",
        "Si vous utilisez des csv vous pouvez décommenter la fonction qui se trouve en dessous qui utilise la fonction :\n",
        "```python\n",
        "data_dict[table] = pd.read_csv(file_path, dtype={'BEN_NIR_PSA': str, 'BEN_NIR_ANO': str})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b779c427",
      "metadata": {
        "id": "b779c427"
      },
      "outputs": [],
      "source": [
        "def load_snds_excel(folder_path):\n",
        "    \"\"\"\n",
        "    Charge tous les fichiers .xlsx correspondant aux tables SNDS\n",
        "    dans un dictionnaire de DataFrames.\n",
        "    \"\"\"\n",
        "    data_dict = {}\n",
        "\n",
        "    for table in tables_snds:\n",
        "        file_path = os.path.join(folder_path, f\"{table}.xlsx\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"Chargement de {table}...\")\n",
        "            # On charge le fichier.\n",
        "            # Note : on force le type string pour les identifiants (NIR) pour éviter de perdre le '0' devant.\n",
        "            data_dict[table] = pd.read_excel(file_path, dtype={'BEN_NIR_PSA': str, 'BEN_NIR_ANO': str}) #Possible ajout de 'NUM_ENQ' : str\n",
        "        else:\n",
        "            print(f\"⚠️ Attention : Le fichier {table}.xlsx est introuvable dans {folder_path}\")\n",
        "\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11a9ac4",
      "metadata": {
        "id": "e11a9ac4",
        "outputId": "6d6155c9-6386-4d73-85c2-ea2ab1f65ad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndef load_snds_csv(folder_path):\\n\\n    #Charge tous les fichiers .csv correspondant aux tables SNDS\\n    #dans un dictionnaire de DataFrames.\\n    data_dict = {}\\n\\n    for table in tables_snds:\\n        file_path = os.path.join(folder_path, f\"{table}.csv\")\\n\\n        if os.path.exists(file_path):\\n            print(f\"Chargement de {table}...\")\\n            # On charge le fichier CSV.\\n            # Note : on force le type string pour les identifiants (NIR) pour éviter de perdre le \\'0\\' devant.\\n            data_dict[table] = pd.read_csv(file_path, dtype={\\'BEN_NIR_PSA\\': str, \\'BEN_NIR_ANO\\': str})\\n        else:\\n            print(f\"⚠️ Attention : Le fichier {table}.csv est introuvable dans {folder_path}\")\\n\\n    return data_dict\\n    '"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "def load_snds_csv(folder_path):\n",
        "\n",
        "    #Charge tous les fichiers .csv correspondant aux tables SNDS\n",
        "    #dans un dictionnaire de DataFrames.\n",
        "    data_dict = {}\n",
        "\n",
        "    for table in tables_snds:\n",
        "        file_path = os.path.join(folder_path, f\"{table}.csv\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"Chargement de {table}...\")\n",
        "            # On charge le fichier CSV.\n",
        "            # Note : on force le type string pour les identifiants (NIR) pour éviter de perdre le '0' devant.\n",
        "            data_dict[table] = pd.read_csv(file_path, dtype={'BEN_NIR_PSA': str, 'BEN_NIR_ANO': str}) #Possible ajout de 'NUM_ENQ' : str\n",
        "        else:\n",
        "            print(f\"⚠️ Attention : Le fichier {table}.csv est introuvable dans {folder_path}\")\n",
        "\n",
        "    return data_dict\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5615bec6",
      "metadata": {
        "id": "5615bec6"
      },
      "source": [
        "Avant de charger les données assurez vous que le chemin est le bon vers vos donnés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74a98ba",
      "metadata": {
        "id": "d74a98ba",
        "outputId": "998cd8db-eaa8-465a-bf9e-5cd4ce5a84df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement de er_prs_f...\n",
            "Chargement de er_pha_f...\n",
            "Chargement de ir_pha_r...\n",
            "Chargement de er_bio_f...\n",
            "Chargement de er_cam_f...\n",
            "Chargement de er_tip_f...\n",
            "Chargement de er_ete_f...\n",
            "Chargement de t_mco23b...\n",
            "Chargement de t_mco23c...\n",
            "Chargement de t_mco23a...\n",
            "Chargement de t_mco23d...\n",
            "Chargement de t_mco22b...\n",
            "Chargement de t_mco22c...\n",
            "Chargement de t_mco22a...\n",
            "Chargement de t_mco22d...\n",
            "Chargement de ir_ben_r...\n"
          ]
        }
      ],
      "source": [
        "path_to_files = \"sample_data\" # chemin modifiable vers le dossier contenant les fichiers SNDS\n",
        "# 1. Charger les données\n",
        "dfs = load_snds_excel(path_to_files)\n",
        "#dfs = load_snds_csv(path_to_files) # Décommentez cette ligne pour charger les fichiers CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2b4a4d9",
      "metadata": {
        "id": "d2b4a4d9"
      },
      "source": [
        "# <u>Filtrage des patients uniques :</u>\n",
        "\n",
        "Pour notre part, nous avons mis en place certains critères d'exclusion afin d'être sûrs de n'avoir que des patients uniques :  \n",
        "* Tous les patients ne commençant pas par MR_PARCOURS_SNDS ou NUM_ANO_PAT  \n",
        "* Tous les BEN_NIR_PSA ayant plusieurs patients rattachés (enfants, jumeaux, …)\n",
        "\n",
        "Nous avons ensuite effectué une liste avec le BEN_NIR_PSA de ces patients, que nous réutiliserons plus tard.\n",
        "\n",
        "La suite de notre code se basera principalement sur le BEN_NIR_PSA, car c'est ce qui nous permet d'avoir des patients uniques. **Si vous utilisez le NUM_ENQ, ce code n'est pas approprié.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed7edac",
      "metadata": {
        "id": "eed7edac",
        "outputId": "310952ec-6b26-4e4e-df72-4b6ae8d129a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de patients avec un seul compte : 998\n",
            "Vérification après filtrage : Nombre de patients avec un seul compte : 947\n"
          ]
        }
      ],
      "source": [
        "# 2. Filtrer IR_BEN_R pour garantir l'unicité du patient\n",
        "if 'ir_ben_r' in dfs:\n",
        "    # On identifie les patients valides\n",
        "    single_user_psa = (\n",
        "        dfs['ir_ben_r']\n",
        "        .groupby('BEN_NIR_PSA')['BEN_NIR_ANO']\n",
        "        .nunique()\n",
        "        .loc[lambda x: x == 1]  # Filtre les comptes = 1\n",
        "        .index\n",
        "        .tolist()\n",
        "    )\n",
        "    single_user_psa.append('MR_PARCOURS_SNDS')\n",
        "    print(f\"Nombre de patients avec un seul compte : {len(single_user_psa)}\")\n",
        "    # On filtre la table de référence\n",
        "    filtered_df = dfs['ir_ben_r'][\n",
        "        (dfs['ir_ben_r']['BEN_NIR_PSA'].isin(single_user_psa)) &\n",
        "        (\n",
        "        (dfs['ir_ben_r']['BEN_NIR_PSA'].astype(str).str.startswith(\"NUM_ANO_PAT\")) |\n",
        "        (dfs['ir_ben_r']['BEN_NIR_PSA'].astype(str).str.startswith(\"MR_PARCOURS_SNDS\"))\n",
        "        )\n",
        "    ].drop_duplicates('BEN_NIR_PSA')\n",
        "\n",
        "    # Inclure également les lignes où BEN_NIR_PSA est exactement MR_PARCOURS_SNDS\n",
        "    mr_parcours_df = dfs['ir_ben_r'][dfs['ir_ben_r']['BEN_NIR_PSA'] == 'MR_PARCOURS_SNDS'].drop_duplicates('BEN_NIR_PSA')\n",
        "\n",
        "    # Concaténer les deux DataFrames\n",
        "    filtered_df = pd.concat([filtered_df, mr_parcours_df]).drop_duplicates('BEN_NIR_PSA')\n",
        "\n",
        "    filtered_user_psa = (\n",
        "        filtered_df\n",
        "        .groupby('BEN_NIR_PSA')['BEN_NIR_ANO']\n",
        "        .nunique()\n",
        "        .loc[lambda x: x == 1]  # Filtre les comptes = 1\n",
        "        .index\n",
        "        .tolist()\n",
        "    )\n",
        "    print(f\"Vérification après filtrage : Nombre de patients avec un seul compte : {len(filtered_user_psa)}\")\n",
        "else:\n",
        "    print(\"Erreur : La table ir_ben_r est indispensable pour le filtrage.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea16458",
      "metadata": {
        "id": "fea16458"
      },
      "source": [
        "# <u>Création d'une table concaténée avec les bonnes colonnes</u>\n",
        "L'objectif de cette partie est de concaténer les différentes tables ambulatoires (er_prs_f, er_pha_f, ir_pha_r, er_bio_f, er_cam_f, er_tip_f, er_ete_f).\n",
        "\n",
        "Pour ce faire, nous avons utilisé les clés de jointure suivantes :  \n",
        "* FLX_EMT_TYP  \n",
        "* FLX_EMT_NUM  \n",
        "* REM_TYP_AFF  \n",
        "* FLX_EMT_ORD  \n",
        "* FLX_TRT_DTD  \n",
        "* DCT_ORD_NUM  \n",
        "* PRS_ORD_NUM  \n",
        "* FLX_DIS_DTD  \n",
        "* ORG_CLE_NUM  \n",
        "\n",
        "Afin de diminuer la taille de er_prs_f, qui est de loin la table la plus volumineuse, nous avons présélectionné les colonnes nécessaires. Si d'autres colonnes vous intéressent, vous pouvez modifier cette partie du code :  \n",
        "```python\n",
        "er_prs_f_filtered = er_prs_f_filtered[\n",
        "    ['BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD',\n",
        "     'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM',\n",
        "     'EXE_SOI_DTD', 'EXE_SOI_DTF', 'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT',\n",
        "     'BSE_REM_PRU', 'CPL_REM_MNT', 'PRS_PAI_MNT', 'BSE_PRS_NAT', 'CPL_PRS_NAT',\n",
        "     'DPN_QLF', 'PRS_NAT_REF', 'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT', 'PSP_SPE_COD']\n",
        "]\n",
        "\n",
        "Il est cependant essentiel de garder les 13 premières :\n",
        "'BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM',"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f00f38e",
      "metadata": {
        "id": "7f00f38e"
      },
      "outputs": [],
      "source": [
        "# 1. Filtrer er_prs_f avec les colonnes d'identité et les clés de jointure\n",
        "er_prs_f_filtered = dfs['er_prs_f'][dfs['er_prs_f']['BEN_NIR_PSA'].isin(filtered_user_psa)] #changer les 2 'er_prs_f' si le nom de votre table est différente\n",
        "\n",
        "# Sélection des colonnes souhaitées, adaptable selon les besoins\n",
        "er_prs_f_filtered = er_prs_f_filtered[\n",
        "    ['BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM','EXE_SOI_DTD', 'EXE_SOI_DTF', # ne pas modifier ces lignes\n",
        "     'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT', 'BSE_REM_PRU', 'CPL_REM_MNT', # peut être modifié\n",
        "     'PRS_PAI_MNT', 'BSE_PRS_NAT', 'CPL_PRS_NAT', 'DPN_QLF', 'PRS_NAT_REF',     # peut être modifié\n",
        "     'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT', 'PSP_SPE_COD']                # peut être modifié\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a52a29",
      "metadata": {
        "id": "27a52a29"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 2. Jointure avec er_pha_f\n",
        "er_pha_f = dfs['er_pha_f'] #changer le 'er_pha_f' si le nom de votre table est différente\n",
        "er_pha_f_merged = pd.merge(\n",
        "    er_prs_f_filtered,\n",
        "    er_pha_f,\n",
        "    on=['FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 3. Jointure avec ir_pha_r\n",
        "ir_pha_r = dfs['ir_pha_r'] #changer le 'ir_pha_r' si le nom de votre table est différente\n",
        "final_df = pd.merge(\n",
        "    er_pha_f_merged,\n",
        "    ir_pha_r,\n",
        "    left_on='PHA_PRS_C13',\n",
        "    right_on='PHA_CIP_C13',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 4. Jointure avec er_bio_f\n",
        "er_bio_f = dfs['er_bio_f'] #changer le 'er_bio_f' si le nom de votre table est différente\n",
        "final_df = pd.merge(\n",
        "    final_df,\n",
        "    er_bio_f,\n",
        "    on=['FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 5. Jointure avec er_cam_f\n",
        "er_cam_f = dfs['er_cam_f'] #changer le 'er_cam_f' si le nom de votre table est différente\n",
        "final_df = pd.merge(\n",
        "    final_df,\n",
        "    er_cam_f,\n",
        "    on=['FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 6. Jointure avec er_tip_f\n",
        "er_tip_f = dfs['er_tip_f'] #changer le 'er_tip_f' si le nom de votre table est différente\n",
        "final_df = pd.merge(\n",
        "    final_df,\n",
        "    er_tip_f,\n",
        "    on=['FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 7. Jointure avec er_ete_f\n",
        "er_ete_f = dfs['er_ete_f'] #changer le 'er_ete_f' si le nom de votre table est différente\n",
        "final_df = pd.merge(\n",
        "    final_df,\n",
        "    er_ete_f,\n",
        "    on=['FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM'],\n",
        "    how='left'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa09f9a",
      "metadata": {
        "id": "2fa09f9a"
      },
      "source": [
        "## Tableau ambulatoire\n",
        "Ci-dessous, voici le choix de l'ordre des colonnes du tableau que nous considérons utile pour notre analyse :\n",
        "\n",
        "Dans er_pha_f :  \n",
        "'PHA_ACT_PRU', 'PHA_ACT_QSN', 'PHA_CPA_PCP', 'PHA_PRS_C13', 'PHA_SEQ_RNV',\n",
        "\n",
        "Dans ir_pha_r :  \n",
        "'PHA_ATC_LIB', 'PHA_ATC_L03',\n",
        "\n",
        "Dans er_bio_f :  \n",
        "'BIO_ACT_QSN', 'BIO_PRS_IDE', 'ARO_THE_TAU',\n",
        "\n",
        "Dans er_cam_f :  \n",
        "'CAM_ACT_PRU', 'CAM_PRS_IDE',\n",
        "\n",
        "Dans er_tip_f :  \n",
        "'TIP_PRS_IDE', 'TIP_ACT_QSN',\n",
        "\n",
        "Dans er_ete_f :  \n",
        "'DDP_COD', 'MDT_COD', 'ETE_TYP_COD'\n",
        "\n",
        "### **Si vous devez changer les colonnes :**\n",
        "\n",
        "**Étape 1 :**  \n",
        "Copiez-collez votre sélection de er_prs_f faite précédemment :\n",
        "```python\n",
        "'BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD',  \n",
        "'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM',  \n",
        "'EXE_SOI_DTD', 'EXE_SOI_DTF'                                                # ne pas modifier ces lignes  \n",
        "'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT', 'BSE_REM_PRU', 'CPL_REM_MNT',  # peut être modifié  \n",
        "'PRS_PAI_MNT', 'BSE_PRS_NAT', 'CPL_PRS_NAT', 'DPN_QLF', 'PRS_NAT_REF',      # peut être modifié  \n",
        "'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT', 'PSP_SPE_COD'                  # peut être modifié  \n",
        "```\n",
        "**Étape 2 :**  \n",
        "Choisissez les colonnes utiles dans les autres tables (ici, tout peut être modifié).\n",
        "\n",
        "**Étape 3 :**  \n",
        "Mettez-les dans l'ordre que vous souhaitez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32b879d",
      "metadata": {
        "id": "d32b879d"
      },
      "outputs": [],
      "source": [
        "# 8. Sélectionner les colonnes utiles dans le bon ordre\n",
        "final_df = final_df[\n",
        "    ['BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD',\n",
        "     'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM',\n",
        "     'EXE_SOI_DTD', 'EXE_SOI_DTF', 'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT',\n",
        "     'BSE_REM_PRU', 'CPL_REM_MNT', 'PRS_PAI_MNT', 'BSE_PRS_NAT', 'CPL_PRS_NAT',\n",
        "     'DPN_QLF', 'PRS_NAT_REF', 'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT', 'PSP_SPE_COD',\n",
        "     'PHA_ACT_PRU', 'PHA_ACT_QSN', 'PHA_CPA_PCP', 'PHA_PRS_C13', 'PHA_ATC_LIB', 'PHA_ATC_L03', 'PHA_SEQ_RNV',\n",
        "     'BIO_ACT_QSN', 'BIO_PRS_IDE', 'ARO_THE_TAU', 'CAM_ACT_PRU', 'CAM_PRS_IDE',\n",
        "     'TIP_PRS_IDE', 'TIP_ACT_QSN', 'DDP_COD', 'MDT_COD', 'ETE_TYP_COD']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39fda82",
      "metadata": {
        "id": "a39fda82",
        "outputId": "160cc9c2-d5b1-4090-d978-0841137c1009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9869\n"
          ]
        }
      ],
      "source": [
        "print(len(final_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795720f9",
      "metadata": {
        "id": "795720f9"
      },
      "source": [
        "**Vous pouvez enregistrer ce tableau sous format Excel en décommentant la case ci-dessous.**\n",
        "\n",
        "Vous pourrez déjà effectuer une analyse des tables ambulatoires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c262e5",
      "metadata": {
        "id": "85c262e5"
      },
      "outputs": [],
      "source": [
        "final_df.to_excel(\"Tableau_ambulatoire.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c6453f",
      "metadata": {
        "id": "f0c6453f"
      },
      "source": [
        "# <u>Séquences d'actes pour chaque patient, hospitalisations comprises</u>\n",
        "Dans cette partie, nous allons ajouter les hospitalisations et créer un fichier pour chaque patient, ce qui nous permettra de faire de la visualisation individuelle.\n",
        "\n",
        "Dans les hospitalisations, nous avons utilisé les tables :  \n",
        "* t_mcoxxb : NBR_SEA, DGN_PAL, DGN_REL, GRG_GHM, SEJ_NBJ, ENT_MOD, ENT_PRV, SOR_MOD  \n",
        "* t_mcoxxc : NIR_ANO_17, RNG_NAI, rsa_num, ETA_NUM, HOS_EXE_SOI_DTF, HOS_EXE_SOI_DTD  \n",
        "* t_mcoxxa : CDC_ACT, NBR_EXE_ACT  \n",
        "* t_mcoxxd : ASS_DGN  \n",
        "\n",
        "En utilisant comme clés de jointure :  \n",
        "* rsa_num  \n",
        "* ETA_NUM  \n",
        "\n",
        "**PS : HOS_EXE_SOI_DTF et HOS_EXE_SOI_DTD sont nommées EXE_SOI_DTF et EXE_SOI_DTD dans la table t_mcoxxc, mais ont dû être changées dans le code afin d'éviter les redondances de noms de colonnes.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86e0fec",
      "metadata": {
        "id": "e86e0fec"
      },
      "source": [
        "Vous pouvez trouver ci-dessous les colonnes que nous avons utilisées dans notre automatisation.  \n",
        "Si vous souhaitez les modifier, ce sont les mêmes règles que celles vues précédemment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e22c93e",
      "metadata": {
        "id": "2e22c93e"
      },
      "outputs": [],
      "source": [
        "# Liste des colonnes pour les prestations ambulatoires\n",
        "colonnes_ambulatoires = [\n",
        "    'BEN_NIR_PSA', 'BEN_RNG_GEM', 'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF',                              # ne pas modifier ces lignes\n",
        "    'FLX_EMT_ORD', 'FLX_TRT_DTD', 'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD',                              # ne pas modifier ces lignes\n",
        "    'ORG_CLE_NUM', 'EXE_SOI_DTD', 'EXE_SOI_DTF',                                                            # ne pas modifier ces lignes\n",
        "    'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT', 'BSE_REM_PRU', 'CPL_REM_MNT', 'PRS_PAI_MNT', 'BSE_PRS_NAT',# peut être modifié\n",
        "    'CPL_PRS_NAT', 'DPN_QLF', 'PRS_NAT_REF', 'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT',                   # peut être modifié\n",
        "    'PSP_SPE_COD', 'PHA_ACT_PRU', 'PHA_ACT_QSN', 'PHA_CPA_PCP', 'PHA_PRS_C13', 'PHA_ATC_LIB',               # peut être modifié\n",
        "    'PHA_ATC_L03', 'PHA_SEQ_RNV', 'BIO_ACT_QSN', 'BIO_PRS_IDE', 'ARO_THE_TAU', 'CAM_ACT_PRU',               # peut être modifié\n",
        "    'CAM_PRS_IDE', 'TIP_PRS_IDE', 'TIP_ACT_QSN', 'DDP_COD', 'MDT_COD', 'ETE_TYP_COD'                        # peut être modifié\n",
        "]\n",
        "\n",
        "# Liste des colonnes pour les hospitalisations\n",
        "colonnes_hospitalisations = [\n",
        "    'NIR_ANO_17', 'RNG_NAI', 'rsa_num', 'ETA_NUM', 'HOS_EXE_SOI_DTF', 'HOS_EXE_SOI_DTD',    # ne pas modifier ces lignes\n",
        "    'NBR_SEA', 'DGN_PAL', 'DGN_REL', 'GRG_GHM', 'SEJ_NBJ','ENT_MOD',                        # peut être modifié\n",
        "    'ENT_PRV', 'SOR_MOD', 'CDC_ACT', 'NBR_EXE_ACT', 'ASS_DGN'                               # peut être modifié\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d175166",
      "metadata": {
        "id": "1d175166"
      },
      "outputs": [],
      "source": [
        "# Fonction pour traiter les hospitalisations pour une année donnée\n",
        "def process_mco_year(year, tables):\n",
        "    mco_c = dfs[tables['c']]\n",
        "    mco_c_filtered = mco_c[mco_c['NIR_ANO_17'].isin(filtered_user_psa)]\n",
        "\n",
        "    mco_b = dfs[tables['b']]\n",
        "    mco_b_filtered = mco_b[mco_b['rsa_num'].isin(mco_c_filtered['rsa_num']) &\n",
        "                           mco_b['ETA_NUM'].isin(mco_c_filtered['ETA_NUM'])]\n",
        "\n",
        "    mco_a = dfs[tables['a']]\n",
        "    mco_a_filtered = mco_a[mco_a['rsa_num'].isin(mco_c_filtered['rsa_num']) &\n",
        "                           mco_a['ETA_NUM'].isin(mco_c_filtered['ETA_NUM'])]\n",
        "\n",
        "    mco_d = dfs[tables['d']]\n",
        "    mco_d_filtered = mco_d[mco_d['rsa_num'].isin(mco_c_filtered['rsa_num']) &\n",
        "                           mco_d['ETA_NUM'].isin(mco_c_filtered['ETA_NUM'])]\n",
        "\n",
        "    # Jointure des tableaux MCO\n",
        "    mco_merged = pd.merge(\n",
        "        mco_c_filtered,\n",
        "        mco_b_filtered,\n",
        "        on=['rsa_num', 'ETA_NUM'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    mco_merged = pd.merge(\n",
        "        mco_merged,\n",
        "        mco_a_filtered,\n",
        "        on=['rsa_num', 'ETA_NUM'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    mco_merged = pd.merge(\n",
        "        mco_merged,\n",
        "        mco_d_filtered,\n",
        "        on=['rsa_num', 'ETA_NUM'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Ajouter une colonne pour indiquer l'année\n",
        "    mco_merged['ANNEE'] = year\n",
        "\n",
        "    # Renommer les colonnes en conflit\n",
        "    mco_merged = mco_merged.rename(columns={\n",
        "        'EXE_SOI_DTF': 'HOS_EXE_SOI_DTF',\n",
        "        'EXE_SOI_DTD': 'HOS_EXE_SOI_DTD'\n",
        "    })\n",
        "\n",
        "    return mco_merged[colonnes_hospitalisations]\n",
        "\n",
        "# Traiter les hospitalisations pour chaque année\n",
        "hospitalisations_23 = process_mco_year('23', {'a': 't_mco23a', 'b': 't_mco23b', 'c': 't_mco23c', 'd': 't_mco23d'}) #changer les 't_mco23x' si le nom de votre table est différente\n",
        "hospitalisations_22 = process_mco_year('22', {'a': 't_mco22a', 'b': 't_mco22b', 'c': 't_mco22c', 'd': 't_mco22d'}) #changer les 't_mco23x' si le nom de votre table est différente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d293f6",
      "metadata": {
        "id": "c0d293f6"
      },
      "outputs": [],
      "source": [
        "# Concaténer les hospitalisations des deux années\n",
        "all_hospitalisations = pd.concat([hospitalisations_23, hospitalisations_22], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df8b9c3",
      "metadata": {
        "id": "6df8b9c3"
      },
      "source": [
        "**Vous pouvez enregistrer ce tableau sous format Excel en décommentant la case ci-dessous.**\n",
        "\n",
        "Vous pourrez déjà effectuer une analyse des tables d'hospitalisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57f22fa",
      "metadata": {
        "id": "d57f22fa"
      },
      "outputs": [],
      "source": [
        "all_hospitalisations.to_excel(\"Tableau_hospitalisation.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e045a5",
      "metadata": {
        "id": "f1e045a5"
      },
      "source": [
        "# <u>Tableaux par patient avec l'ensemble des actes </u>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette partie, nous allons créer un tableau récapitulatif regroupant l’ensemble des actes pour tous les patients, qu’ils soient ambulatoires ou liés à une hospitalisation.\n",
        "Il est également possible de générer un tableau individuel par patient en décommentant la section dédiée du code.\n",
        "```python\n",
        "# Exporter le fichier individuel (optionnel)\n",
        "    safe_psa = re.sub(r'[\\\\/*?:\"<>|]', '', str(psa))\n",
        "    file_path = os.path.join(\"parcours_patients\", f\"parcours_{safe_psa}.xlsx\")\n",
        "    patient_data.to_excel(file_path, index=False)\n",
        "    print(f\"Parcours pour le patient {psa} exporté dans {file_path}.\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "G98Zl4ipNPug"
      },
      "id": "G98Zl4ipNPug"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici une traduction des lignes choisis :    \n",
        "\n",
        "TYPE → TYPE (Hospitalisation ou Ambulatoire)\n",
        "\n",
        "BEN_NIR_PSA → Identifiant anonyme du patient dans le SNIIRAM\n",
        "\n",
        "BEN_RNG_GEM → Rang du bénéficiaire\n",
        "\n",
        "rsa_num → N° d'index du RSA\n",
        "\n",
        "ETA_NUM → Numéro FINESS ePMSI\n",
        "\n",
        "HOS_EXE_SOI_DTD → Date d'exécution des soins hospitaliers\n",
        "\n",
        "FLX_EMT_TYP → Type de flux émis\n",
        "\n",
        "FLX_EMT_NUM → Numéro du flux émis\n",
        "\n",
        "REM_TYP_AFF → Type de remboursement affilié\n",
        "\n",
        "FLX_EMT_ORD → Ordre du flux émis\n",
        "\n",
        "FLX_TRT_DTD → Date d'entrée des données dans le système d'information\n",
        "\n",
        "DCT_ORD_NUM → Numéro d'ordre du décompte dans l'organisme\n",
        "\n",
        "PRS_ORD_NUM → Numéro d'ordre de la prestation dans le décompte\n",
        "\n",
        "FLX_DIS_DTD → Date de mise à disposition du flux\n",
        "\n",
        "ORG_CLE_NUM → Ancien organisme avant fusion (jusqu’au jour J de la fusion)\n",
        "\n",
        "EXE_SOI_DTD → Date d'exécution des soins\n",
        "\n",
        "EXE_SOI_DTF → Date de fin d'exécution des soins\n",
        "\n",
        "PRE_PRE_DTD → Date de prescription\n",
        "\n",
        "PRS_HOS_DTD → Date de début d'hospitalisation\n",
        "\n",
        "BSE_REM_MNT → Montant de base du remboursement\n",
        "\n",
        "BSE_REM_PRU → Prix unitaire de l'acte (acte de base)\n",
        "\n",
        "CPL_REM_MNT → Montant complémentaire du remboursement\n",
        "\n",
        "PRS_PAI_MNT → Montant payé par la personne\n",
        "\n",
        "BSE_PRS_NAT → Nature de base de la personne\n",
        "\n",
        "CPL_PRS_NAT → Nature complémentaire de la personne\n",
        "\n",
        "DPN_QLF → Qualificatif de la dépense\n",
        "\n",
        "PRS_NAT_REF → Nature de la prestation de référence\n",
        "\n",
        "PSE_ACT_NAT → Nature de l'activité du professionnel de santé\n",
        "\n",
        "PSE_SPE_COD → Code de spécialité du professionnel de santé\n",
        "\n",
        "PSP_ACT_NAT → Nature de l'activité du prestataire de santé\n",
        "\n",
        "PSP_SPE_COD → Code de spécialité du prestataire de santé\n",
        "\n",
        "PHA_ACT_PRU → Prix unitaire de la prestation affinée de pharmacie\n",
        "\n",
        "PHA_ACT_QSN → Quantité affinée signée de l'activité pharmaceutique\n",
        "\n",
        "PHA_CPA_PCP → Condition particulière de prise en charge pharmaceutique\n",
        "\n",
        "PHA_PRS_C13 → Code prestation affinée (CIP 13)\n",
        "\n",
        "PHA_ATC_LIB → Libellé ATC (Classification Anatomique Thérapeutique Chimique)\n",
        "\n",
        "PHA_ATC_L03 → Code ATC niveau 3\n",
        "\n",
        "PHA_SEQ_RNV → Séquence de renouvellement pharmaceutique\n",
        "\n",
        "BIO_ACT_QSN → Quantité affinée signée de biologie\n",
        "\n",
        "BIO_PRS_IDE → Identifiant de la prestation affinée de biologie\n",
        "\n",
        "ARO_THE_TAU → Taux thérapeutique ARO\n",
        "\n",
        "CAM_ACT_PRU → Prix unitaire de l'activité CCAM\n",
        "\n",
        "CAM_PRS_IDE → Identifiant de la prestation affinée CCAM\n",
        "\n",
        "TIP_PRS_IDE → Identifiant de la prestation affinée TIP\n",
        "\n",
        "TIP_ACT_QSN → Quantité affinée signée TIP\n",
        "\n",
        "DDP_COD → Discipline de Prs ou DMT\n",
        "\n",
        "MDT_COD → Mode de Traitement\n",
        "\n",
        "ETE_TYP_COD → Type d'établissement de rattachement de l'exécutant ou lieu d'exécution des soins\n",
        "\n",
        "HOS_EXE_SOI_DTF → Date de fin d'exécution des soins hospitaliers\n",
        "\n",
        "NBR_SEA → Nombre de séances\n",
        "\n",
        "DGN_PAL → Diagnostic principal\n",
        "\n",
        "DGN_REL → Diagnostic relié\n",
        "\n",
        "GRG_GHM → Groupe Homogène de Malades (GHM)\n",
        "\n",
        "SEJ_NBJ → Nombre de jours de séjour\n",
        "\n",
        "ENT_MOD → Mode d'entrée\n",
        "\n",
        "ENT_PRV → Provenance\n",
        "\n",
        "SOR_MOD → Mode de sortie\n",
        "\n",
        "CDC_ACT → Code CCAM (hors extension PMSI)\n",
        "\n",
        "NBR_EXE_ACT → Nombre d'exécutions d'activité\n",
        "\n",
        "ASS_DGN → Diagnostic associé\n",
        "\n",
        "Pour des informations complémentaire sur les lignes : https://health-data-hub.shinyapps.io/dico-snds/"
      ],
      "metadata": {
        "id": "4F0O56qdQz1P"
      },
      "id": "4F0O56qdQz1P"
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"parcours_patients\", exist_ok=True)  # Vous pouvez modifier le nom du dossier et son emplacement si besoin\n",
        "# Initialiser une liste pour stocker les DataFrames des patients\n",
        "all_patients_data = []\n",
        "\n",
        " # Liste des colonnes dans l'ordre souhaité\n",
        "\n",
        "\n",
        "# Itérer sur chaque BEN_NIR_PSA unique\n",
        "for psa in filtered_user_psa:\n",
        "    # Filtrer les données pour le BEN_NIR_PSA actuel\n",
        "    patient_ambulatoire = final_df[final_df['BEN_NIR_PSA'] == psa][colonnes_ambulatoires].copy()\n",
        "    patient_hospitalisations = all_hospitalisations[all_hospitalisations['NIR_ANO_17'] == psa].copy()\n",
        "\n",
        "    # Ajouter une colonne pour indiquer le type de données\n",
        "    patient_ambulatoire['TYPE'] = 'Ambulatoire'\n",
        "    patient_hospitalisations['TYPE'] = 'Hospitalisation'\n",
        "\n",
        "    # Renommer NIR_ANO_17 et RNG_NAI pour les hospitalisations\n",
        "    patient_hospitalisations.rename(columns={'NIR_ANO_17': 'BEN_NIR_PSA', 'RNG_NAI': 'BEN_RNG_GEM'}, inplace=True)\n",
        "\n",
        "    # Ajouter une colonne de date commune pour le tri chronologique\n",
        "    patient_ambulatoire['DATE'] = patient_ambulatoire['EXE_SOI_DTD']\n",
        "    patient_hospitalisations['DATE'] = patient_hospitalisations['HOS_EXE_SOI_DTD']\n",
        "\n",
        "    # Concaténer les données ambulatoires et hospitalisations\n",
        "    patient_data = pd.concat([patient_ambulatoire, patient_hospitalisations], ignore_index=True)\n",
        "\n",
        "    # Trier les actes par ordre chronologique\n",
        "    patient_data.sort_values(by='DATE', inplace=True)\n",
        "\n",
        "    # Supprimer la colonne temporaire 'DATE' après le tri\n",
        "    patient_data.drop(columns=['DATE'], inplace=True)\n",
        "\n",
        "    colonnes_souhaitees = [\n",
        "        'TYPE', 'BEN_NIR_PSA', 'BEN_RNG_GEM', 'rsa_num', 'ETA_NUM', 'HOS_EXE_SOI_DTD',\n",
        "        'FLX_EMT_TYP', 'FLX_EMT_NUM', 'REM_TYP_AFF', 'FLX_EMT_ORD', 'FLX_TRT_DTD',\n",
        "        'DCT_ORD_NUM', 'PRS_ORD_NUM', 'FLX_DIS_DTD', 'ORG_CLE_NUM', 'EXE_SOI_DTD',\n",
        "        'EXE_SOI_DTF', 'PRE_PRE_DTD', 'PRS_HOS_DTD', 'BSE_REM_MNT', 'BSE_REM_PRU',\n",
        "        'CPL_REM_MNT', 'PRS_PAI_MNT', 'BSE_PRS_NAT', 'CPL_PRS_NAT', 'DPN_QLF',\n",
        "        'PRS_NAT_REF', 'PSE_ACT_NAT', 'PSE_SPE_COD', 'PSP_ACT_NAT', 'PSP_SPE_COD',\n",
        "        'PHA_ACT_PRU', 'PHA_ACT_QSN', 'PHA_CPA_PCP', 'PHA_PRS_C13', 'PHA_ATC_LIB',\n",
        "        'PHA_ATC_L03', 'PHA_SEQ_RNV', 'BIO_ACT_QSN', 'BIO_PRS_IDE', 'ARO_THE_TAU',\n",
        "        'CAM_ACT_PRU', 'CAM_PRS_IDE', 'TIP_PRS_IDE', 'TIP_ACT_QSN', 'DDP_COD',\n",
        "        'MDT_COD', 'ETE_TYP_COD', 'HOS_EXE_SOI_DTF', 'NBR_SEA', 'DGN_PAL', 'DGN_REL',\n",
        "        'GRG_GHM', 'SEJ_NBJ', 'ENT_MOD', 'ENT_PRV', 'SOR_MOD', 'CDC_ACT',\n",
        "        'NBR_EXE_ACT', 'ASS_DGN'\n",
        "    ]\n",
        "\n",
        "    # Réorganiser les colonnes du DataFrame patient_data\n",
        "    patient_data = patient_data[colonnes_souhaitees]\n",
        "\n",
        "    # Ajouter le DataFrame du patient à la liste\n",
        "    all_patients_data.append(patient_data)\n",
        "\n",
        "    # Exporter le fichier individuel (optionnel)\n",
        "    #safe_psa = re.sub(r'[\\\\/*?:\"<>|]', '', str(psa))\n",
        "    #file_path = os.path.join(\"parcours_patients\", f\"parcours_{safe_psa}.xlsx\")\n",
        "    #patient_data.to_excel(file_path, index=False)\n",
        "    #print(f\"Parcours pour le patient {psa} exporté dans {file_path}.\")\n",
        "\n",
        "# Concaténer tous les DataFrames en un seul\n",
        "all_patients_concatenated = pd.concat(all_patients_data, ignore_index=True)\n",
        "\n",
        "# Chemin pour le fichier concaténé\n",
        "output_file = os.path.join(\"parcours_patients\", \"tous_les_parcours_patients.xlsx\")\n",
        "\n",
        "# Exporter le DataFrame concaténé en Excel\n",
        "all_patients_concatenated.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Tous les parcours patients ont été concaténés et exportés dans {output_file}.\")\n"
      ],
      "metadata": {
        "id": "9ZeNgxbnILUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62fdb52-8825-4715-8224-0e3de0855d50"
      },
      "id": "9ZeNgxbnILUn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tous les parcours patients ont été concaténés et exportés dans parcours_patients/tous_les_parcours_patients.xlsx.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}